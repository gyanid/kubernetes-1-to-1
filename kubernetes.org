#+Title: Learning Kubernetes
#+Date: <2018-09-22 Sat>
#+Author: Yogesh Agrawal
#+Email: yogeshiiith@gmail.com

* Introduction
  Here will be learning kubernetes.

* Concepts
  - Kubernetes improves the development, delivery and maintenance of
    distributed applications.

  - Basics: pods, labels, annotations, services and replicasets.

  - Advanced: Daemon sets, jobs, configMaps, Secrets.
 
  - Deployments: lifecycly of a complete application.

  - Storage.

  - Based on three principles: immutability, declarative
    configurationm and online self healing systems.

  - Immutability: Once an artifact is created in the system it does
    not change via user modifications.

  - There are no incremental changes.

  - Immutable container images are at the core of everything that we
    will build in Kubernetes.

  - Everything in kubernetes is a declarative configuration object
    that represents the desired state of the system. It is kubernete's
    job to ensure that the actual state of the world matches the
    desired state.

  - Imperative defines actions, declarative defines state.

  - When it receives a desired state config, it does not take actions
    to make the current state match the desired state. It continuously
    takes actions to ensure that the curent state matches the desired
    state.

  - Combining three variable growth rates into a single growth rate
    reduces statistical noise and produces a more reliable forecast of
    expected growth.

  - Efficiency can be measured by the ratio of the useful work
    performed by machine or process to the total amount of energy
    spent doing so.

  - A dockerfile can be used to automate the creation of a Docker
    container image.

  - While designing a docker file, order your layers from least likely
    to change to most likely to change in order to optimize the image
    size for pushing and pulling.

* Kubernets Components
  #+BEGIN_SRC bash
$ kubectl get componentstatuses
NAME                 STATUS    MESSAGE              ERROR
controller-manager   Healthy   ok                   
scheduler            Healthy   ok                   
etcd-0               Healthy   {"health": "true"}
  #+END_SRC
** controller-manager
   It is responsible for running various controllers that regulate
   behavior in the cluster: for example, ensuring that all of the
   replicas of a service are available and healthy.

** scheduler
   The scheduler is responsible for placing different pods onto
   different nodes in the cluster.

** etcd server
   It is the storage for the cluster where all of the API objects are
   stored.

* Kubernetes Nodes
   #+BEGIN_SRC bash
$ kubectl get nodes
NAME       STATUS    ROLES     AGE       VERSION
minikube   Ready     master    12d       v1.10.0
   #+END_SRC
 
   In Kubernetes nodes are separated into master nodes that containe
   containers like the API server, scheduler, etc., which manage the
   cluster, and worker nodes where your containers will
   run. Kubernetes won't generally schedule work onto master nodes to
   ensure that user workloads don't harm the overall operation of the
   cluster.

* Cluster Components
** Kubernetes Proxy
   The kubernetes proxy is responsible for routing network traffic to
   load-balanced services in the Kubernetes cluster. To do its job,
   the proxy must be present on every node in the cluster. Kubernetes
   has an API object named =DaemonSet=, which we will learn about
   later.
   #+BEGIN_SRC bash
$ kubectl get daemonSets --namespace=kube-system kube-proxy
NAME         DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE
kube-proxy   1         1         1         1            1           <none>          12d
   #+END_SRC

** Kubernetes DNS
   Kubernetes also runs a DNS server, which provides naming and
   discovery for the services that are defined in the cluster. This
   DNS server also runs as a replicated service on the
   cluster. Depending on the size of your cluster, you may see one or
   more DNS servers running in your cluster. The DNS service is run as
   a Kubernetes deployment, which manages these replicas:
   #+BEGIN_SRC bash
$ kubectl get deployments --namespace=kube-system kube-dns
NAME       DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
kube-dns   1         1         1            1           12d
   #+END_SRC

   There is also a Kuberenetes service that performs load-balancing
   for the DNS server:
   #+BEGIN_SRC bash
$ kubectl get services --namespace=kube-system kube-dns
NAME       TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)         AGE
kube-dns   ClusterIP   10.96.0.10   <none>        53/UDP,53/TCP   12d
   #+END_SRC

   This shows that the DNS service for the cluster has the address
   =10.96.0.10=. If we log into a container in the cluster, we will
   see that the this has been polpulated into the =/etc/resolv.conf=
   file for the container.

** Kubernetes UI
   The final kubernetes components is a GUI. The UI is run as a single
   replica, but it is still managed by a Kubernetes deployment for
   reliability and upgrades.

   We can use the kubectl proxy to acces this UI.
   #+BEGIN_SRC bash
   $ kubectl proxy
   #+END_SRC

* Kubectl commands
** Namespaces
   Kubernetes uses =namespaces= to organize objects in the cluster. We
   can think of each namespace as a folder that holds a set of
   objects. By default, the kubectl command-line tool interacts with
   the default namespace. We can pass =--namespace= flag to refer a
   particular namespace.

** Contexts
   If we want to change the default namespace more permanently, we can
   use a context. This gets recorded in a kubectl configuration file,
   usually located at =$HOME/.kube/config=. This configuration file
   also stores how to both find and authenticate to your cluster. For
   example, we can create context with a different default namespace
   for your kubectl commands using:

   #+BEGIN_SRC bash
   $ kubectl config set-context my-context --namespace=mystuff
   #+END_SRC

   This creates a new context, but it doesn't actually start using it
   yet. To use this newly created context, we can run:
   #+BEGIN_SRC bash
   $ kubectl config use-context my-context
   #+END_SRC

   Contexts can also be used to manage different clusters or different
   users for authenticating to those clusters using the =--users= or
   =--clusters= flags with the =set-context= command.

** Viewing objects
   #+BEGIN_SRC bash
   $ kubectl get pods my-pod -o yaml
   $ kubectl get pods my-pod -o jsonpath --template={.status.podIP}
   $ kubectl describe <resource-name> <obj-name>
   #+END_SRC

** Creating, updating and destroying
   #+BEGIN_SRC bash
   $ kubectl apply -f obj.yaml
   $ kubectl delete -f obj.yaml
   $ kubectl delete <resource-name> <obj-name>
   #+END_SRC

** Labelling and annotating objects
   #+BEGIN_SRC bash
   $ kubectl label pods bar color=red
   $ kubectl label pods bar color-
   $ kubectl annotate pods bar color=red
   #+END_SRC

** Debugging commands
   #+BEGIN_SRC bash
   $ kubectl logs <pod-name>
   $ kubectl logs <pod-name> -f
   $ kubectl exec -it <pod-name> -- bash
   $ kubectl cp <pod-name>:/path/to/remote/file /path/to/local/file
   #+END_SRC

* Pods
  A pod represents a collection of application containers and volumes
  running in the same execution environment. Pods, not containers, are
  the smallest deployable artifact in a kubernetes cluster. This means
  all of the containers in a Pod always land on the same machine.

  Each container within a Pod runs in its own cgroup, but they share a
  number of Linux namespaces.

  Applications running in the same Pod share the same IP address and
  port space (network namespace), have the same hostname (UTS
  namespace), and can communicate using native interprocess
  communication channels over System V IPC or POSIX message queues
  (IPC namespace). However, applications in different Pods are
  isolated from each other; they have different IP addresses,
  different hostnames, and more. Containers in different Pods running
  on the same node might as well be on different servers.

** Thinking with Pods
   In general, the right question to ask yourself when designing Pods
   is, "Will these containers work correctly if they land on different
   machines? If the answer is "no", a Pod is the correct grouping for
   the containers. If the answer is "yes", multiple Pods is probably
   the correct solution.

** The Pod manifest
   Pods are described in a Pod manifest. The Pod manifest is just a
   text-file representation of the Kubernetes API object.

** Creating a Pod
   #+BEGIN_SRC bash
   $ kubectl run kuard --image=gcr.io/kuar-demo/kuard-amd64:1
   $ kubectl get pods
   $ kubectl delete deployments/kuard
   #+END_SRC

** Creating a Pod Manifest
   Pod manifests can be written using YAML or JSON, but YAML is
   generally preferred because it is slightly more human-editable and
   has the ability to add comments.

   Pod manifests include a couple of key fields and attributes: mainly
   a =metadata= section for describing the Pod and its labels, a
   =spec= section for describing volumes, and a list of containers
   that will run in the Pod.

   #+BEGIN_SRC YAML
apiVersion: v1
kind: Pod
metadata:
  name: kuard
spec:
  containers:
    - image: gcr.io/kuar-demo/kuard-amd64:1
      name: kuard
      ports:
        - containerPort: 8080
          name: http
          protocol: TCP
   #+END_SRC

** Running Pods
   #+BEGIN_SRC bash
$ kubectl apply -f kuard-pod.yaml
   #+END_SRC

   The Pod manifest will be submitted to Kubernetes API server. The
   Kubernetes system will then schedule that Pod to run on a healthy
   node in the cluster, where it will be monitored by the =kubelet=
   daemon process.

** Listing Pods
   #+BEGIN_SRC bash
$ kubectl get pods
NAME                                     READY     STATUS        RESTARTS   AGE
kuard                                    1/1       Running       0          7m
   #+END_SRC

   The =Pending= state indicates that the Pod has been submitted but
   hasn't been scheduled yet.

** Pod Details
   #+BEGIN_SRC bash
$ kubectl describe pods kuard
   #+END_SRC
   
   This outputs a bunch of information about the Pod in different
   sections. At the top is basic information about the Pod.
   #+BEGIN_EXAMPLE
   Name:         kuard
Namespace:    default
Node:         minikube/192.168.64.2
Start Time:   Sun, 23 Sep 2018 10:57:17 +0100
Labels:       <none>
Annotations:  kubectl.kubernetes.io/last-applied-configuration={"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"name":"kuard","namespace":"default"},"spec":{"containers":[{"image":"gcr.io/kuar-demo/kua...
Status:       Running
IP:           172.17.0.8
   #+END_EXAMPLE

   Then there is information abuot the containers running in the Pod.
   #+BEGIN_EXAMPLE
   Containers:
  kuard:
    Container ID:   docker://b141a676a5c0537cfd967fc4fb0b4e0ec7b8c8a532c103a8b58f43aeeac3ec50
    Image:          gcr.io/kuar-demo/kuard-amd64:1
    Image ID:       docker-pullable://gcr.io/kuar-demo/kuard-amd64@sha256:3e75660dfe00ba63d0e6b5db2985a7ed9c07c3e115faba291f899b05db0acd91
    Port:           8080/TCP
    State:          Running
      Started:      Sun, 23 Sep 2018 10:57:18 +0100
    Ready:          True
    Restart Count:  0
    Environment:    <none>
    Mounts:
      /var/run/secrets/kubernetes.io/serviceaccount from default-token-7vr8q (ro)
   #+END_EXAMPLE

   Finally, there are events related to the Pod, such as when it was
   scheduled, when its image was pulled, and if/when it had to be
   restarted because of failing health checks.
   #+BEGIN_EXAMPLE
   Events:
  Type    Reason                 Age   From               Message
  ----    ------                 ----  ----               -------
  Normal  Scheduled              10m   default-scheduler  Successfully assigned kuard to minikube
  Normal  SuccessfulMountVolume  10m   kubelet, minikube  MountVolume.SetUp succeeded for volume "default-token-7vr8q"
  Normal  Pulled                 10m   kubelet, minikube  Container image "gcr.io/kuar-demo/kuard-amd64:1" already present on machine
  Normal  Created                10m   kubelet, minikube  Created container
  Normal  Started                10m   kubelet, minikube  Started container
   #+END_EXAMPLE

** Deleting a Pod
   #+BEGIN_SRC bash
$ kubectl delete pods/kuard
$ kubectl delete -f kuard-pod.yaml
   #+END_SRC

   All Pods have a termination =grace period=. By default, this is 30
   seconds. When a Pod is transitioned to =Terminating= it no longer
   receives new requests. In a serving scenario, the grace period is
   important for reliability because it allows the Pod to finish any
   active requests that it may be in the middle of processing before
   it is terminated.
   
   It's important to note that when you delete a Pod, any data stored
   in the containers associated with that Pod will be deleted as
   well. If you want to persist data across multiple instances of a
   Pod, you need to use =PersistentVolumes=.

** Accessing your Pod
*** Using Port Forwarding
    We can use the port-forwarding support built into the Kubernetes
    API and command-line tools. When we run
    #+BEGIN_SRC bash
$ kubectl port-forward kuard 8080:8080
    #+END_SRC
    a secure tunnel is created from our local machine, through the
    Kubernetes master, to the instance of the Pod running on one of
    the worker nodes.

*** Getting more info with logs
    When application needs debugging, it's helpful to be able to dig
    deeper that =describe= to understand what the application is
    doing. Kubernetes provides two commands for debugging running
    containers. The =kubectl logs= command downloads the current logs
    from the running instance:
    #+BEGIN_SRC bash
$ kubectl logs kuard
    #+END_SRC

    Adding the =-f= flag will cause you to continuously stream
    logs. The =kubectl logs= command always tries to get logs from the
    currently running container. Adding the =--previous= flag will get
    logs from a previous instance of the container.

*** Running commands in container with exec
    Sometimes logs are insufficient, and to truly determine what's
    going on you need to execute commands in the context of the
    container itself.
    #+BEGIN_SRC bash
$ kubectl exec kuard date
    #+END_SRC
    
    You can also get an interactive session by adding the =-it= flags.
    #+BEGIN_SRC bash
$ kubectl exec -it ash
    #+END_SRC

*** Copying files to and from containers
    #+BEGIN_SRC bash
$ kubectl cp <pod-name>:/captures/capture3.txt ./capture3.txt
$ kubectl cp $HOME/config.txt <pod-name>:/config.txt
    #+END_SRC

* Command cheatsheet
  #+BEGIN_SRC bash
  $ kubectl get componentstatuses
  $ kubectl get nodes
  $ kubectl describe nodes node-1
  $ kubectl get daemonSets --namespace=kube-system kube-proxy
  $ kubectl get pods --namespace=kube-system
  $ kubectl get deployments --namespace=kube-system kube-dns
  $ kubectl get services --namespace=kube-system kube-dns
  $ kubectl get deployments --namespace=kube-system kubernetes-dashboard
  $ kubectl get services --namespace=kube-system
  $ kubectl proxy
  $ kubectl get pods --no-headers
  $ kubectl get pods -o yaml
  $ kubecetl describe pods <my-pod>
  $ kubectl label pods <pod> color=red
  $ kubectl label pods <pod> label-
  $ kubectl logs <pod-name>
  $ kubectl logs <pod-name> -f
  $ kubectl exec -it <pod-name> -- bash
  $ kubectl cp <pod-name>:/path/to/remote/file /path/to/local/file
  $ kubectl help
  $ kubectl help command-name
  #+END_SRC

  #+BEGIN_SRC bash
  $ kubectl config current-context
  $ kubectl config use-context mas-qa/oshift-api-jfk3-qa-bamtech-co:8443/yagrawal
  $ kubectl config view
  $ kubectl -n razcp-dev get deployment razcp-hello-world-app-chart -o yaml
  $ kubectl get componentstatuses
  #+END_SRC

* References
  1. Kubernetes Up & Running book.
